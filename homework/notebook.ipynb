{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.murillo_bluet\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samuel.murillo_bluet\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para el dataset Entrenamiento:\n",
      "Accuracy: 0.8148\n",
      "Precision: 0.6939\n",
      "Recall: 0.3196\n",
      "F1 Score: 0.4376\n",
      "----------------------------------------\n",
      "Métricas para el dataset prueba:\n",
      "Accuracy: 0.8304\n",
      "Precision: 0.7018\n",
      "Recall: 0.3494\n",
      "F1 Score: 0.4665\n",
      "----------------------------------------\n",
      "Matriz de Confusión para el dataset :\n",
      "[[6790  283]\n",
      " [1240  666]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import Functions\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    # Paso 1: Cargar los datos\n",
    "\n",
    "    data_test= Functions.load_data(\"../files/input/test_data.csv.zip\")\n",
    "    data_train= Functions.load_data(\"../files/input/train_data.csv.zip\")\n",
    "    # Paso 2: Limpiar los datos\n",
    "    data_test = Functions.clean_data(data_test)\n",
    "    data_train = Functions.clean_data(data_train)\n",
    "    # paso 3: dividir los datos \n",
    "    x_test=data_test.drop(\"default\", axis=1)\n",
    "    y_test=data_test[[\"default\"]]\n",
    "    x_train=data_train.drop(\"default\", axis=1)\n",
    "    y_train=data_train[[\"default\"]]\n",
    "\n",
    "    pipeline = Functions.make_pipeline(\n",
    "        estimator=LogisticRegression(n_jobs=-1, random_state=666,class_weight=None))\n",
    "    pipeline\n",
    "    # Paso 5: Definir los hiperparámetros para la búsqueda en cuadrícula\n",
    "\n",
    "    param_grid = {\n",
    "        #'estimator__penalty': ['l1', 'l2'],  # Aquí agregamos el nombre del paso 'estimator__' \n",
    "        'estimator__C': [1],\n",
    "        'estimator__solver': ['lbfgs'],\n",
    "        #'estimator__max_iter': [100, 200],\n",
    "    }\n",
    "\n",
    "\n",
    "    # Paso 6: Crear el objeto GridSearchCV\n",
    "\n",
    "    estimator = Functions.make_grid_search(estimator=pipeline, param_grid=param_grid, cv=10)\n",
    "\n",
    "    # Paso 7: Ajustar el modelo a los datos de entrenamiento\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # Paso 8: Obtener el mejor estimador\n",
    "    best_estimator = Functions.load_estimator_compressed()\n",
    "\n",
    "    if best_estimator is not None:\n",
    "\n",
    "        saved_balanced_accuracy = balanced_accuracy_score(\n",
    "            y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        current_balanced_accuracy = balanced_accuracy_score(\n",
    "            y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        if current_balanced_accuracy < saved_balanced_accuracy:\n",
    "            estimator = best_estimator\n",
    "\n",
    "    Functions.save_estimator_compressed(estimator)\n",
    "\n",
    "    # Ejecutar cálculo de métricas y matrices\n",
    "    Functions.calculate_and_save_metrics(estimator, x_train, x_test, y_train, y_test)\n",
    "    Functions.calculate_and_save_confusion_matrices(estimator, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # Paso 1: Obtener el mejor modelo de GridSearchCV\n",
    "    best_model = estimator.best_estimator_\n",
    "\n",
    "    # Paso 2: Hacer predicciones con el mejor modelo\n",
    "    y_train_pred = best_model.predict(x_train)\n",
    "    y_test_pred = best_model.predict(x_test)\n",
    "    # Imprimir métricas para el conjunto de entrenamiento\n",
    "    Functions.print_metric(y_train, y_train_pred, 'Entrenamiento')\n",
    "    Functions.print_metric(y_test, y_test_pred, 'prueba')\n",
    "\n",
    "    # Imprimir métricas para el conjunto de prueba\n",
    "    Functions.print_confusion_matrix(y_test, y_test_pred, '')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
